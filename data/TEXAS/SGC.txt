! python main.py --compare_model=1 --cuda_num=0 --N_exp=1 --type_model=SGC --dataset=TEXAS

+-------------------+---------------------+
| Parameter         | Value               |
+-------------------+---------------------+
| N_exp             | 1                   |
+-------------------+---------------------+
| activation        | relu                |
+-------------------+---------------------+
| adj_dropout       | 0.500               |
+-------------------+---------------------+
| alpha             | 0.100               |
+-------------------+---------------------+
| compare_model     | 1                   |
+-------------------+---------------------+
| cuda              | 1                   |
+-------------------+---------------------+
| cuda_num          | 0                   |
+-------------------+---------------------+
| dataset           | TEXAS               |
+-------------------+---------------------+
| dim_hidden        | 64                  |
+-------------------+---------------------+
| dropout           | 0.500               |
+-------------------+---------------------+
| edge_dropout      | 0.200               |
+-------------------+---------------------+
| embedding_dropout | 0.600               |
+-------------------+---------------------+
| epochs            | 1000                |
+-------------------+---------------------+
| graph_dropout     | 0.200               |
+-------------------+---------------------+
| has_residual_MLP  | 0                   |
+-------------------+---------------------+
| lamda             | 0.500               |
+-------------------+---------------------+
| layer_agg         | concat              |
+-------------------+---------------------+
| layerwise_dropout | 0                   |
+-------------------+---------------------+
| log_file_name     | time_and_memory.log |
+-------------------+---------------------+
| lr                | 0.010               |
+-------------------+---------------------+
| multi_label       | 0                   |
+-------------------+---------------------+
| node_norm_type    | n                   |
+-------------------+---------------------+
| num_classes       | 5                   |
+-------------------+---------------------+
| num_feats         | 1703                |
+-------------------+---------------------+
| num_groups        | None                |
+-------------------+---------------------+
| num_layers        | 64                  |
+-------------------+---------------------+
| patience          | 100                 |
+-------------------+---------------------+
| random_seed       | 100                 |
+-------------------+---------------------+
| res_alpha         | 0.900               |
+-------------------+---------------------+
| resume            | 0                   |
+-------------------+---------------------+
| skip_weight       | None                |
+-------------------+---------------------+
| transductive      | 1                   |
+-------------------+---------------------+
| type_model        | SGC                 |
+-------------------+---------------------+
| type_norm         | None                |
+-------------------+---------------------+
| type_trick        | None                |
+-------------------+---------------------+
| weight_decay      | 0.000               |
+-------------------+---------------------+
| weight_decay1     | 0.010               |
+-------------------+---------------------+
| weight_decay2     | 0.001               |
+-------------------+---------------------+
seed (which_run) = <0>
Epoch: 000, Train loss: 1.6082, Val loss: 1.5984, Test acc: 0.6486
Epoch: 001, Train loss: 1.5968, Val loss: 1.5903, Test acc: 0.6486
Epoch: 020, Train loss: 1.4188, Val loss: 1.4612, Test acc: 0.6486
Epoch: 040, Train loss: 1.2985, Val loss: 1.3741, Test acc: 0.6486
Epoch: 060, Train loss: 1.2298, Val loss: 1.3285, Test acc: 0.6486
Epoch: 080, Train loss: 1.1760, Val loss: 1.3063, Test acc: 0.6486
Epoch: 100, Train loss: 1.1610, Val loss: 1.2930, Test acc: 0.6216
Epoch: 120, Train loss: 1.1428, Val loss: 1.2848, Test acc: 0.6216
Epoch: 140, Train loss: 1.1214, Val loss: 1.2771, Test acc: 0.6216
Epoch: 160, Train loss: 1.1272, Val loss: 1.2707, Test acc: 0.6216
Epoch: 180, Train loss: 1.0690, Val loss: 1.2651, Test acc: 0.6216
Epoch: 200, Train loss: 1.0875, Val loss: 1.2615, Test acc: 0.6216
Epoch: 220, Train loss: 1.0688, Val loss: 1.2598, Test acc: 0.6216
Epoch: 240, Train loss: 1.0510, Val loss: 1.2593, Test acc: 0.6216
Epoch: 260, Train loss: 1.0878, Val loss: 1.2578, Test acc: 0.6216
Epoch: 280, Train loss: 1.0669, Val loss: 1.2553, Test acc: 0.6216
Epoch: 300, Train loss: 1.0757, Val loss: 1.2540, Test acc: 0.6216
Epoch: 320, Train loss: 1.0632, Val loss: 1.2535, Test acc: 0.6216
Epoch: 340, Train loss: 1.0628, Val loss: 1.2516, Test acc: 0.6216
Epoch: 360, Train loss: 1.0671, Val loss: 1.2508, Test acc: 0.6216
Epoch: 380, Train loss: 1.0567, Val loss: 1.2514, Test acc: 0.6216
Epoch: 400, Train loss: 1.0443, Val loss: 1.2506, Test acc: 0.6216
Epoch: 420, Train loss: 1.0502, Val loss: 1.2525, Test acc: 0.6216
Epoch: 440, Train loss: 1.0477, Val loss: 1.2522, Test acc: 0.6216
Epoch: 460, Train loss: 1.0295, Val loss: 1.2507, Test acc: 0.6216
Epoch: 480, Train loss: 1.0459, Val loss: 1.2504, Test acc: 0.6216
Epoch: 500, Train loss: 1.0505, Val loss: 1.2474, Test acc: 0.6216
Epoch: 520, Train loss: 1.0536, Val loss: 1.2485, Test acc: 0.6216
Epoch: 540, Train loss: 1.0240, Val loss: 1.2502, Test acc: 0.6216
Epoch: 560, Train loss: 1.0276, Val loss: 1.2510, Test acc: 0.6216
Epoch: 580, Train loss: 1.0596, Val loss: 1.2489, Test acc: 0.6216
Epoch: 600, Train loss: 1.0256, Val loss: 1.2485, Test acc: 0.6216
train_loss: 1.0305, val_acc: 0.6102, test_acc:0.6216
mean and std of test acc: 0.6216±0.0000
final mean and std of test acc with <1> runs: 0.6216±0.0000


(base) 192:eegnn yiruiliu$ python main.py --compare_model=1 --cuda_num=0 --N_exp=1 --type_model=SGC_new --dataset=TEXAS
+-------------------+---------------------+
| Parameter         | Value               |
+-------------------+---------------------+
| N_exp             | 1                   |
+-------------------+---------------------+
| activation        | relu                |
+-------------------+---------------------+
| adj_dropout       | 0.500               |
+-------------------+---------------------+
| alpha             | 0.100               |
+-------------------+---------------------+
| compare_model     | 1                   |
+-------------------+---------------------+
| cuda              | 1                   |
+-------------------+---------------------+
| cuda_num          | 0                   |
+-------------------+---------------------+
| dataset           | TEXAS               |
+-------------------+---------------------+
| dim_hidden        | 64                  |
+-------------------+---------------------+
| dropout           | 0.500               |
+-------------------+---------------------+
| edge_dropout      | 0.200               |
+-------------------+---------------------+
| embedding_dropout | 0.600               |
+-------------------+---------------------+
| epochs            | 1000                |
+-------------------+---------------------+
| graph_dropout     | 0.200               |
+-------------------+---------------------+
| has_residual_MLP  | 0                   |
+-------------------+---------------------+
| lamda             | 0.500               |
+-------------------+---------------------+
| layer_agg         | concat              |
+-------------------+---------------------+
| layerwise_dropout | 0                   |
+-------------------+---------------------+
| log_file_name     | time_and_memory.log |
+-------------------+---------------------+
| lr                | 0.010               |
+-------------------+---------------------+
| multi_label       | 0                   |
+-------------------+---------------------+
| node_norm_type    | n                   |
+-------------------+---------------------+
| num_classes       | 5                   |
+-------------------+---------------------+
| num_feats         | 1703                |
+-------------------+---------------------+
| num_groups        | None                |
+-------------------+---------------------+
| num_layers        | 64                  |
+-------------------+---------------------+
| patience          | 100                 |
+-------------------+---------------------+
| random_seed       | 100                 |
+-------------------+---------------------+
| res_alpha         | 0.900               |
+-------------------+---------------------+
| resume            | 0                   |
+-------------------+---------------------+
| skip_weight       | None                |
+-------------------+---------------------+
| transductive      | 1                   |
+-------------------+---------------------+
| type_model        | SGC_new             |
+-------------------+---------------------+
| type_norm         | None                |
+-------------------+---------------------+
| type_trick        | None                |
+-------------------+---------------------+
| weight_decay      | 0.000               |
+-------------------+---------------------+
| weight_decay1     | 0.010               |
+-------------------+---------------------+
| weight_decay2     | 0.001               |
+-------------------+---------------------+
seed (which_run) = <0>
Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/new_data/texas/out1_node_feature_label.txt
Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/new_data/texas/out1_graph_edges.txt
Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_0.npz
Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_1.npz
Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_2.npz
Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_3.npz
Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_4.npz
Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_5.npz
Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_6.npz
Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_7.npz
Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_8.npz
Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_9.npz
Processing...
Done!
is symmetric: (0 is yes) tensor(0.)
is self connected: 0 is no tensor(183.)
Num Nodes : 183          Num Edges : 350
Epoch: 000, Train loss: 1.6089, Val loss: 1.6043, Test acc: 0.6486
Epoch: 001, Train loss: 1.6024, Val loss: 1.6000, Test acc: 0.6486
Epoch: 020, Train loss: 1.4919, Val loss: 1.5299, Test acc: 0.6486
Epoch: 040, Train loss: 1.4027, Val loss: 1.4754, Test acc: 0.6486
Epoch: 060, Train loss: 1.3420, Val loss: 1.4364, Test acc: 0.6486
Epoch: 080, Train loss: 1.2987, Val loss: 1.4083, Test acc: 0.6486
Epoch: 100, Train loss: 1.2659, Val loss: 1.3877, Test acc: 0.6486
Epoch: 120, Train loss: 1.2356, Val loss: 1.3726, Test acc: 0.6486
Epoch: 140, Train loss: 1.2188, Val loss: 1.3612, Test acc: 0.6486
Epoch: 160, Train loss: 1.1955, Val loss: 1.3524, Test acc: 0.6486
Epoch: 180, Train loss: 1.1890, Val loss: 1.3446, Test acc: 0.6486
Epoch: 200, Train loss: 1.1737, Val loss: 1.3383, Test acc: 0.6486
Epoch: 220, Train loss: 1.1676, Val loss: 1.3334, Test acc: 0.6486
Epoch: 240, Train loss: 1.1586, Val loss: 1.3288, Test acc: 0.6486
Epoch: 260, Train loss: 1.1339, Val loss: 1.3250, Test acc: 0.6486
Epoch: 280, Train loss: 1.1448, Val loss: 1.3218, Test acc: 0.6486
Epoch: 300, Train loss: 1.1364, Val loss: 1.3185, Test acc: 0.6486
Epoch: 320, Train loss: 1.1335, Val loss: 1.3161, Test acc: 0.6486
Epoch: 340, Train loss: 1.1200, Val loss: 1.3129, Test acc: 0.6486
Epoch: 360, Train loss: 1.1248, Val loss: 1.3108, Test acc: 0.6486
Epoch: 380, Train loss: 1.1060, Val loss: 1.3089, Test acc: 0.6486
Epoch: 400, Train loss: 1.1063, Val loss: 1.3079, Test acc: 0.6486
Epoch: 420, Train loss: 1.1246, Val loss: 1.3064, Test acc: 0.6486
Epoch: 440, Train loss: 1.1309, Val loss: 1.3054, Test acc: 0.6486
Epoch: 460, Train loss: 1.0959, Val loss: 1.3040, Test acc: 0.6486
Epoch: 480, Train loss: 1.1134, Val loss: 1.3023, Test acc: 0.6486
Epoch: 500, Train loss: 1.0938, Val loss: 1.3009, Test acc: 0.6486
Epoch: 520, Train loss: 1.0925, Val loss: 1.3000, Test acc: 0.6486
Epoch: 540, Train loss: 1.1060, Val loss: 1.2996, Test acc: 0.6486
Epoch: 560, Train loss: 1.1044, Val loss: 1.2984, Test acc: 0.6486
Epoch: 580, Train loss: 1.1043, Val loss: 1.2976, Test acc: 0.6486
Epoch: 600, Train loss: 1.0947, Val loss: 1.2969, Test acc: 0.6486
Epoch: 620, Train loss: 1.0800, Val loss: 1.2963, Test acc: 0.6486
Epoch: 640, Train loss: 1.1025, Val loss: 1.2953, Test acc: 0.6486
Epoch: 660, Train loss: 1.0977, Val loss: 1.2954, Test acc: 0.6486
Epoch: 680, Train loss: 1.1068, Val loss: 1.2956, Test acc: 0.6486
Epoch: 700, Train loss: 1.0778, Val loss: 1.2952, Test acc: 0.6486
Epoch: 720, Train loss: 1.1031, Val loss: 1.2948, Test acc: 0.6486
Epoch: 740, Train loss: 1.0953, Val loss: 1.2947, Test acc: 0.6486
Epoch: 760, Train loss: 1.1035, Val loss: 1.2945, Test acc: 0.6486
Epoch: 780, Train loss: 1.0967, Val loss: 1.2932, Test acc: 0.6486
Epoch: 800, Train loss: 1.0746, Val loss: 1.2928, Test acc: 0.6486
Epoch: 820, Train loss: 1.0959, Val loss: 1.2927, Test acc: 0.6486
Epoch: 840, Train loss: 1.0807, Val loss: 1.2931, Test acc: 0.6486
Epoch: 860, Train loss: 1.0918, Val loss: 1.2922, Test acc: 0.6486
Epoch: 880, Train loss: 1.0735, Val loss: 1.2918, Test acc: 0.6486
Epoch: 900, Train loss: 1.0786, Val loss: 1.2921, Test acc: 0.6486
Epoch: 920, Train loss: 1.0885, Val loss: 1.2915, Test acc: 0.6486
Epoch: 940, Train loss: 1.0821, Val loss: 1.2909, Test acc: 0.6486
Epoch: 960, Train loss: 1.0742, Val loss: 1.2907, Test acc: 0.6486
Epoch: 980, Train loss: 1.0686, Val loss: 1.2909, Test acc: 0.6486
train_loss: 1.0750, val_acc: 0.5254, test_acc:0.6486
mean and std of test acc: 0.6486±0.0000
final mean and std of test acc with <1> runs: 0.6486±0.0000
