! python main.py --compare_model=1 --cuda_num=0 --N_exp=1 --type_model=GCN --dataset=Citeseer
/content/drive/Othercomputers/My MacBook Pro/pythonProject/utils.py:49: UserWarning: configs of GCN not found, use the default setting instead
  warn(f'configs of {model} not found, use the default setting instead')
/content/drive/Othercomputers/My MacBook Pro/pythonProject/utils.py:56: UserWarning: GCN have no specific settings on Citeseer. Use the default setting instead.
  warn(f'{model} have no specific settings on {dataset}. Use the default setting instead.')
+-------------------+---------------------+
| Parameter         | Value               |
+-------------------+---------------------+
| N_exp             | 1                   |
+-------------------+---------------------+
| activation        | relu                |
+-------------------+---------------------+
| adj_dropout       | 0.500               |
+-------------------+---------------------+
| alpha             | 0.100               |
+-------------------+---------------------+
| compare_model     | 1                   |
+-------------------+---------------------+
| cuda              | 1                   |
+-------------------+---------------------+
| cuda_num          | 0                   |
+-------------------+---------------------+
| dataset           | Citeseer            |
+-------------------+---------------------+
| dim_hidden        | 256                 |
+-------------------+---------------------+
| dropout           | 0.700               |
+-------------------+---------------------+
| edge_dropout      | 0.200               |
+-------------------+---------------------+
| embedding_dropout | 0.600               |
+-------------------+---------------------+
| epochs            | 1000                |
+-------------------+---------------------+
| graph_dropout     | 0.200               |
+-------------------+---------------------+
| has_residual_MLP  | 0                   |
+-------------------+---------------------+
| lamda             | 0.600               |
+-------------------+---------------------+
| layer_agg         | concat              |
+-------------------+---------------------+
| layerwise_dropout | 0                   |
+-------------------+---------------------+
| log_file_name     | time_and_memory.log |
+-------------------+---------------------+
| lr                | 0.010               |
+-------------------+---------------------+
| multi_label       | 0                   |
+-------------------+---------------------+
| node_norm_type    | n                   |
+-------------------+---------------------+
| num_classes       | 6                   |
+-------------------+---------------------+
| num_feats         | 3703                |
+-------------------+---------------------+
| num_groups        | None                |
+-------------------+---------------------+
| num_layers        | 64                  |
+-------------------+---------------------+
| patience          | 100                 |
+-------------------+---------------------+
| random_seed       | 100                 |
+-------------------+---------------------+
| res_alpha         | 0.200               |
+-------------------+---------------------+
| resume            | 0                   |
+-------------------+---------------------+
| skip_weight       | None                |
+-------------------+---------------------+
| transductive      | 1                   |
+-------------------+---------------------+
| type_model        | GCN                 |
+-------------------+---------------------+
| type_norm         | None                |
+-------------------+---------------------+
| type_trick        | None                |
+-------------------+---------------------+
| weight_decay      | 0.001               |
+-------------------+---------------------+
| weight_decay1     | 0.010               |
+-------------------+---------------------+
| weight_decay2     | 0.001               |
+-------------------+---------------------+
seed (which_run) = <0>
Epoch: 000, Train loss: 1.7921, Val loss: 1.7961, Test acc: 0.2310
Epoch: 001, Train loss: 2.0115, Val loss: 1.8090, Test acc: 0.1370
Epoch: 020, Train loss: 1.7843, Val loss: 1.7843, Test acc: 0.1820
Epoch: 040, Train loss: 1.7919, Val loss: 1.7793, Test acc: 0.1810
Epoch: 060, Train loss: 1.7627, Val loss: 1.7851, Test acc: 0.1830
Epoch: 080, Train loss: 1.7689, Val loss: 1.7866, Test acc: 0.1730
Epoch: 100, Train loss: 1.7407, Val loss: 1.7685, Test acc: 0.1840
Epoch: 120, Train loss: 1.7407, Val loss: 1.7737, Test acc: 0.1770
Epoch: 140, Train loss: 1.7478, Val loss: 1.7830, Test acc: 0.1790
Epoch: 160, Train loss: 1.7508, Val loss: 1.7799, Test acc: 0.1800
Epoch: 180, Train loss: 1.7543, Val loss: 1.7754, Test acc: 0.1770
train_loss: 1.7549, val_acc: 0.2360, test_acc:0.1780
mean and std of test acc: 0.1780±0.0000
final mean and std of test acc with <1> runs: 0.1780±0.0000

