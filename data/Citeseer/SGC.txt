(base) 192:eegnn yiruiliu$ python main.py --compare_model=1 --cuda_num=0 --N_exp=1 --type_model=SGC --dataset=Citeseer
+-------------------+---------------------+
| Parameter         | Value               |
+-------------------+---------------------+
| N_exp             | 1                   |
+-------------------+---------------------+
| activation        | relu                |
+-------------------+---------------------+
| adj_dropout       | 0.500               |
+-------------------+---------------------+
| alpha             | 0.100               |
+-------------------+---------------------+
| compare_model     | 1                   |
+-------------------+---------------------+
| cuda              | 1                   |
+-------------------+---------------------+
| cuda_num          | 0                   |
+-------------------+---------------------+
| dataset           | Citeseer            |
+-------------------+---------------------+
| dim_hidden        | 256                 |
+-------------------+---------------------+
| dropout           | 0.700               |
+-------------------+---------------------+
| edge_dropout      | 0.200               |
+-------------------+---------------------+
| embedding_dropout | 0.600               |
+-------------------+---------------------+
| epochs            | 1000                |
+-------------------+---------------------+
| graph_dropout     | 0.200               |
+-------------------+---------------------+
| has_residual_MLP  | 0                   |
+-------------------+---------------------+
| lamda             | 0.600               |
+-------------------+---------------------+
| layer_agg         | concat              |
+-------------------+---------------------+
| layerwise_dropout | 0                   |
+-------------------+---------------------+
| log_file_name     | time_and_memory.log |
+-------------------+---------------------+
| lr                | 0.010               |
+-------------------+---------------------+
| multi_label       | 0                   |
+-------------------+---------------------+
| node_norm_type    | n                   |
+-------------------+---------------------+
| num_classes       | 6                   |
+-------------------+---------------------+
| num_feats         | 3703                |
+-------------------+---------------------+
| num_groups        | None                |
+-------------------+---------------------+
| num_layers        | 64                  |
+-------------------+---------------------+
| patience          | 100                 |
+-------------------+---------------------+
| random_seed       | 100                 |
+-------------------+---------------------+
| res_alpha         | 0.200               |
+-------------------+---------------------+
| resume            | 0                   |
+-------------------+---------------------+
| skip_weight       | None                |
+-------------------+---------------------+
| transductive      | 1                   |
+-------------------+---------------------+
| type_model        | SGC                 |
+-------------------+---------------------+
| type_norm         | None                |
+-------------------+---------------------+
| type_trick        | None                |
+-------------------+---------------------+
| weight_decay      | 0.001               |
+-------------------+---------------------+
| weight_decay1     | 0.010               |
+-------------------+---------------------+
| weight_decay2     | 0.001               |
+-------------------+---------------------+
seed (which_run) = <0>
Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x
Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx
Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx
Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y
Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty
Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally
Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph
Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index
Processing...
Done!
Epoch: 000, Train loss: 1.7915, Val loss: 1.7899, Test acc: 0.6010
Epoch: 001, Train loss: 1.7886, Val loss: 1.7882, Test acc: 0.5810
Epoch: 020, Train loss: 1.7438, Val loss: 1.7701, Test acc: 0.6050
Epoch: 040, Train loss: 1.7217, Val loss: 1.7610, Test acc: 0.5880
Epoch: 060, Train loss: 1.7100, Val loss: 1.7546, Test acc: 0.5930
Epoch: 080, Train loss: 1.7026, Val loss: 1.7505, Test acc: 0.5940
Epoch: 100, Train loss: 1.6949, Val loss: 1.7474, Test acc: 0.6040
Epoch: 120, Train loss: 1.6880, Val loss: 1.7449, Test acc: 0.6030
Epoch: 140, Train loss: 1.6892, Val loss: 1.7424, Test acc: 0.6070
Epoch: 160, Train loss: 1.6888, Val loss: 1.7407, Test acc: 0.6120
Epoch: 180, Train loss: 1.6708, Val loss: 1.7395, Test acc: 0.6140
Epoch: 200, Train loss: 1.6817, Val loss: 1.7385, Test acc: 0.6120
Epoch: 220, Train loss: 1.6691, Val loss: 1.7372, Test acc: 0.6180
Epoch: 240, Train loss: 1.6712, Val loss: 1.7359, Test acc: 0.6190
Epoch: 260, Train loss: 1.6676, Val loss: 1.7354, Test acc: 0.6200
Epoch: 280, Train loss: 1.6614, Val loss: 1.7345, Test acc: 0.6210
Epoch: 300, Train loss: 1.6663, Val loss: 1.7342, Test acc: 0.6200
Epoch: 320, Train loss: 1.6647, Val loss: 1.7335, Test acc: 0.6240
Epoch: 340, Train loss: 1.6656, Val loss: 1.7330, Test acc: 0.6240
Epoch: 360, Train loss: 1.6620, Val loss: 1.7329, Test acc: 0.6190
Epoch: 380, Train loss: 1.6704, Val loss: 1.7327, Test acc: 0.6210
Epoch: 400, Train loss: 1.6742, Val loss: 1.7322, Test acc: 0.6230
Epoch: 420, Train loss: 1.6717, Val loss: 1.7318, Test acc: 0.6290
Epoch: 440, Train loss: 1.6777, Val loss: 1.7312, Test acc: 0.6310
Epoch: 460, Train loss: 1.6711, Val loss: 1.7311, Test acc: 0.6290
Epoch: 480, Train loss: 1.6657, Val loss: 1.7313, Test acc: 0.6230
Epoch: 500, Train loss: 1.6722, Val loss: 1.7310, Test acc: 0.6260
Epoch: 520, Train loss: 1.6716, Val loss: 1.7307, Test acc: 0.6310
Epoch: 540, Train loss: 1.6622, Val loss: 1.7305, Test acc: 0.6280
Epoch: 560, Train loss: 1.6716, Val loss: 1.7304, Test acc: 0.6280
Epoch: 580, Train loss: 1.6631, Val loss: 1.7299, Test acc: 0.6300
Epoch: 600, Train loss: 1.6667, Val loss: 1.7298, Test acc: 0.6310
Epoch: 620, Train loss: 1.6747, Val loss: 1.7299, Test acc: 0.6330
Epoch: 640, Train loss: 1.6706, Val loss: 1.7296, Test acc: 0.6260
Epoch: 660, Train loss: 1.6552, Val loss: 1.7295, Test acc: 0.6270
Epoch: 680, Train loss: 1.6686, Val loss: 1.7292, Test acc: 0.6280
Epoch: 700, Train loss: 1.6466, Val loss: 1.7292, Test acc: 0.6310
Epoch: 720, Train loss: 1.6709, Val loss: 1.7293, Test acc: 0.6300
Epoch: 740, Train loss: 1.6744, Val loss: 1.7290, Test acc: 0.6260
Epoch: 760, Train loss: 1.6595, Val loss: 1.7290, Test acc: 0.6310
Epoch: 780, Train loss: 1.6748, Val loss: 1.7283, Test acc: 0.6300
Epoch: 800, Train loss: 1.6705, Val loss: 1.7278, Test acc: 0.6330
Epoch: 820, Train loss: 1.6554, Val loss: 1.7282, Test acc: 0.6270
Epoch: 840, Train loss: 1.6716, Val loss: 1.7279, Test acc: 0.6310
Epoch: 860, Train loss: 1.6639, Val loss: 1.7280, Test acc: 0.6320
Epoch: 880, Train loss: 1.6605, Val loss: 1.7284, Test acc: 0.6300
Epoch: 900, Train loss: 1.6723, Val loss: 1.7282, Test acc: 0.6270
Epoch: 920, Train loss: 1.6640, Val loss: 1.7280, Test acc: 0.6240
Epoch: 940, Train loss: 1.6718, Val loss: 1.7280, Test acc: 0.6250
train_loss: 1.6636, val_acc: 0.6340, test_acc:0.6310
mean and std of test acc: 0.6310±0.0000
final mean and std of test acc with <1> runs: 0.6310±0.0000

(base) 192:eegnn yiruiliu$ python main.py --compare_model=1 --cuda_num=0 --N_exp=1 --type_model=SGC_new --dataset=Citeseer
+-------------------+---------------------+
| Parameter         | Value               |
+-------------------+---------------------+
| N_exp             | 1                   |
+-------------------+---------------------+
| activation        | relu                |
+-------------------+---------------------+
| adj_dropout       | 0.500               |
+-------------------+---------------------+
| alpha             | 0.100               |
+-------------------+---------------------+
| compare_model     | 1                   |
+-------------------+---------------------+
| cuda              | 1                   |
+-------------------+---------------------+
| cuda_num          | 0                   |
+-------------------+---------------------+
| dataset           | Citeseer            |
+-------------------+---------------------+
| dim_hidden        | 256                 |
+-------------------+---------------------+
| dropout           | 0.700               |
+-------------------+---------------------+
| edge_dropout      | 0.200               |
+-------------------+---------------------+
| embedding_dropout | 0.600               |
+-------------------+---------------------+
| epochs            | 1000                |
+-------------------+---------------------+
| graph_dropout     | 0.200               |
+-------------------+---------------------+
| has_residual_MLP  | 0                   |
+-------------------+---------------------+
| lamda             | 0.600               |
+-------------------+---------------------+
| layer_agg         | concat              |
+-------------------+---------------------+
| layerwise_dropout | 0                   |
+-------------------+---------------------+
| log_file_name     | time_and_memory.log |
+-------------------+---------------------+
| lr                | 0.010               |
+-------------------+---------------------+
| multi_label       | 0                   |
+-------------------+---------------------+
| node_norm_type    | n                   |
+-------------------+---------------------+
| num_classes       | 6                   |
+-------------------+---------------------+
| num_feats         | 3703                |
+-------------------+---------------------+
| num_groups        | None                |
+-------------------+---------------------+
| num_layers        | 64                  |
+-------------------+---------------------+
| patience          | 100                 |
+-------------------+---------------------+
| random_seed       | 100                 |
+-------------------+---------------------+
| res_alpha         | 0.200               |
+-------------------+---------------------+
| resume            | 0                   |
+-------------------+---------------------+
| skip_weight       | None                |
+-------------------+---------------------+
| transductive      | 1                   |
+-------------------+---------------------+
| type_model        | SGC_new             |
+-------------------+---------------------+
| type_norm         | None                |
+-------------------+---------------------+
| type_trick        | None                |
+-------------------+---------------------+
| weight_decay      | 0.001               |
+-------------------+---------------------+
| weight_decay1     | 0.010               |
+-------------------+---------------------+
| weight_decay2     | 0.001               |
+-------------------+---------------------+
seed (which_run) = <0>
is symmetric: (0 is yes) tensor(0.)
is self connected: 0 is no tensor(3327.)
Num Nodes : 3327         Num Edges : 7879
Epoch: 000, Train loss: 1.7915, Val loss: 1.7898, Test acc: 0.5420
Epoch: 001, Train loss: 1.7885, Val loss: 1.7880, Test acc: 0.5680
Epoch: 020, Train loss: 1.7421, Val loss: 1.7689, Test acc: 0.6060
Epoch: 040, Train loss: 1.7170, Val loss: 1.7584, Test acc: 0.6080
Epoch: 060, Train loss: 1.7034, Val loss: 1.7513, Test acc: 0.6130
Epoch: 080, Train loss: 1.6941, Val loss: 1.7463, Test acc: 0.6210
Epoch: 100, Train loss: 1.6910, Val loss: 1.7427, Test acc: 0.6230
Epoch: 120, Train loss: 1.6762, Val loss: 1.7399, Test acc: 0.6270
Epoch: 140, Train loss: 1.6712, Val loss: 1.7370, Test acc: 0.6340
Epoch: 160, Train loss: 1.6735, Val loss: 1.7351, Test acc: 0.6380
Epoch: 180, Train loss: 1.6771, Val loss: 1.7338, Test acc: 0.6390
Epoch: 200, Train loss: 1.6708, Val loss: 1.7327, Test acc: 0.6370
Epoch: 220, Train loss: 1.6657, Val loss: 1.7317, Test acc: 0.6360
Epoch: 240, Train loss: 1.6637, Val loss: 1.7303, Test acc: 0.6410
Epoch: 260, Train loss: 1.6592, Val loss: 1.7292, Test acc: 0.6420
Epoch: 280, Train loss: 1.6717, Val loss: 1.7282, Test acc: 0.6410
Epoch: 300, Train loss: 1.6674, Val loss: 1.7276, Test acc: 0.6490
Epoch: 320, Train loss: 1.6663, Val loss: 1.7271, Test acc: 0.6480
Epoch: 340, Train loss: 1.6664, Val loss: 1.7266, Test acc: 0.6550
Epoch: 360, Train loss: 1.6649, Val loss: 1.7260, Test acc: 0.6530
Epoch: 380, Train loss: 1.6732, Val loss: 1.7259, Test acc: 0.6490
Epoch: 400, Train loss: 1.6680, Val loss: 1.7261, Test acc: 0.6440
Epoch: 420, Train loss: 1.6573, Val loss: 1.7256, Test acc: 0.6430
Epoch: 440, Train loss: 1.6621, Val loss: 1.7246, Test acc: 0.6460
Epoch: 460, Train loss: 1.6596, Val loss: 1.7247, Test acc: 0.6380
Epoch: 480, Train loss: 1.6582, Val loss: 1.7249, Test acc: 0.6420
Epoch: 500, Train loss: 1.6526, Val loss: 1.7246, Test acc: 0.6440
Epoch: 520, Train loss: 1.6607, Val loss: 1.7245, Test acc: 0.6400
Epoch: 540, Train loss: 1.6678, Val loss: 1.7243, Test acc: 0.6360
Epoch: 560, Train loss: 1.6542, Val loss: 1.7245, Test acc: 0.6360
Epoch: 580, Train loss: 1.6716, Val loss: 1.7240, Test acc: 0.6370
Epoch: 600, Train loss: 1.6508, Val loss: 1.7238, Test acc: 0.6400
Epoch: 620, Train loss: 1.6745, Val loss: 1.7235, Test acc: 0.6400
Epoch: 640, Train loss: 1.6573, Val loss: 1.7231, Test acc: 0.6530
Epoch: 660, Train loss: 1.6536, Val loss: 1.7228, Test acc: 0.6510
Epoch: 680, Train loss: 1.6558, Val loss: 1.7226, Test acc: 0.6410
Epoch: 700, Train loss: 1.6593, Val loss: 1.7224, Test acc: 0.6450
Epoch: 720, Train loss: 1.6593, Val loss: 1.7225, Test acc: 0.6530
Epoch: 740, Train loss: 1.6562, Val loss: 1.7226, Test acc: 0.6560
Epoch: 760, Train loss: 1.6508, Val loss: 1.7224, Test acc: 0.6480
Epoch: 780, Train loss: 1.6645, Val loss: 1.7222, Test acc: 0.6490
Epoch: 800, Train loss: 1.6586, Val loss: 1.7217, Test acc: 0.6570
Epoch: 820, Train loss: 1.6638, Val loss: 1.7216, Test acc: 0.6510
Epoch: 840, Train loss: 1.6535, Val loss: 1.7219, Test acc: 0.6480
Epoch: 860, Train loss: 1.6661, Val loss: 1.7218, Test acc: 0.6450
Epoch: 880, Train loss: 1.6674, Val loss: 1.7218, Test acc: 0.6490
Epoch: 900, Train loss: 1.6433, Val loss: 1.7213, Test acc: 0.6490
Epoch: 920, Train loss: 1.6562, Val loss: 1.7209, Test acc: 0.6580
Epoch: 940, Train loss: 1.6630, Val loss: 1.7215, Test acc: 0.6470
Epoch: 960, Train loss: 1.6488, Val loss: 1.7219, Test acc: 0.6480
Epoch: 980, Train loss: 1.6536, Val loss: 1.7218, Test acc: 0.6490
train_loss: 1.6623, val_acc: 0.6560, test_acc:0.6540
mean and std of test acc: 0.6540±0.0000
final mean and std of test acc with <1> runs: 0.6540±0.0000
