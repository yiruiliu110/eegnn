! python main.py --compare_model=1 --cuda_num=0 --N_exp=1 --type_model=GCNII --dataset=Pubmed


+-------------------+---------------------+
| Parameter         | Value               |
+-------------------+---------------------+
| N_exp             | 1                   |
+-------------------+---------------------+
| activation        | relu                |
+-------------------+---------------------+
| adj_dropout       | 0.500               |
+-------------------+---------------------+
| alpha             | 0.100               |
+-------------------+---------------------+
| compare_model     | 1                   |
+-------------------+---------------------+
| cuda              | 1                   |
+-------------------+---------------------+
| cuda_num          | 0                   |
+-------------------+---------------------+
| dataset           | Pubmed              |
+-------------------+---------------------+
| dim_hidden        | 256                 |
+-------------------+---------------------+
| dropout           | 0.600               |
+-------------------+---------------------+
| edge_dropout      | 0.200               |
+-------------------+---------------------+
| embedding_dropout | 0.600               |
+-------------------+---------------------+
| epochs            | 1000                |
+-------------------+---------------------+
| graph_dropout     | 0.200               |
+-------------------+---------------------+
| has_residual_MLP  | 0                   |
+-------------------+---------------------+
| lamda             | 0.400               |
+-------------------+---------------------+
| layer_agg         | concat              |
+-------------------+---------------------+
| layerwise_dropout | 0                   |
+-------------------+---------------------+
| log_file_name     | time_and_memory.log |
+-------------------+---------------------+
| lr                | 0.010               |
+-------------------+---------------------+
| multi_label       | 0                   |
+-------------------+---------------------+
| node_norm_type    | n                   |
+-------------------+---------------------+
| num_classes       | 3                   |
+-------------------+---------------------+
| num_feats         | 500                 |
+-------------------+---------------------+
| num_groups        | None                |
+-------------------+---------------------+
| num_layers        | 64                  |
+-------------------+---------------------+
| patience          | 100                 |
+-------------------+---------------------+
| random_seed       | 100                 |
+-------------------+---------------------+
| resume            | 0                   |
+-------------------+---------------------+
| skip_weight       | None                |
+-------------------+---------------------+
| transductive      | 1                   |
+-------------------+---------------------+
| type_model        | GCNII               |
+-------------------+---------------------+
| type_norm         | None                |
+-------------------+---------------------+
| type_trick        | None                |
+-------------------+---------------------+
| weight_decay      | 0.001               |
+-------------------+---------------------+
| weight_decay1     | 0.001               |
+-------------------+---------------------+
| weight_decay2     | 0.001               |
+-------------------+---------------------+
seed (which_run) = <0>
Epoch: 000, Train loss: 1.0978, Val loss: 1.0994, Test acc: 0.1850
Epoch: 001, Train loss: 1.0983, Val loss: 1.0964, Test acc: 0.3530
Epoch: 020, Train loss: 0.8482, Val loss: 0.9102, Test acc: 0.7260
Epoch: 040, Train loss: 0.5274, Val loss: 0.6883, Test acc: 0.7550
Epoch: 060, Train loss: 0.3992, Val loss: 0.6297, Test acc: 0.7770
Epoch: 080, Train loss: 0.3880, Val loss: 0.5842, Test acc: 0.7850
Epoch: 100, Train loss: 0.2840, Val loss: 0.5481, Test acc: 0.7990
Epoch: 120, Train loss: 0.2946, Val loss: 0.5541, Test acc: 0.7830
Epoch: 140, Train loss: 0.2883, Val loss: 0.5430, Test acc: 0.7930
Epoch: 160, Train loss: 0.3129, Val loss: 0.5271, Test acc: 0.8010
Epoch: 180, Train loss: 0.2197, Val loss: 0.5325, Test acc: 0.7970
Epoch: 200, Train loss: 0.3033, Val loss: 0.5424, Test acc: 0.7910
Epoch: 220, Train loss: 0.2685, Val loss: 0.5268, Test acc: 0.7950
Epoch: 240, Train loss: 0.2302, Val loss: 0.5225, Test acc: 0.7930
Epoch: 260, Train loss: 0.2679, Val loss: 0.5221, Test acc: 0.7940
Epoch: 280, Train loss: 0.2450, Val loss: 0.5222, Test acc: 0.7960
Epoch: 300, Train loss: 0.2327, Val loss: 0.5195, Test acc: 0.8020
Epoch: 320, Train loss: 0.2326, Val loss: 0.5321, Test acc: 0.7890
Epoch: 340, Train loss: 0.2415, Val loss: 0.5631, Test acc: 0.7880
Epoch: 360, Train loss: 0.2647, Val loss: 0.5232, Test acc: 0.7950
Epoch: 380, Train loss: 0.2491, Val loss: 0.5245, Test acc: 0.7900
Epoch: 400, Train loss: 0.2480, Val loss: 0.5548, Test acc: 0.7810
Epoch: 420, Train loss: 0.1780, Val loss: 0.5190, Test acc: 0.7920
Epoch: 440, Train loss: 0.2268, Val loss: 0.5087, Test acc: 0.8000
Epoch: 460, Train loss: 0.1709, Val loss: 0.5188, Test acc: 0.7950
train_loss: 0.2015, val_acc: 0.8100, test_acc:0.7980
mean and std of test acc: 0.7980±0.0000
final mean and std of test acc with <1> runs: 0.7980±0.0000