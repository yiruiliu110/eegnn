! python main.py --compare_model=1 --cuda_num=0 --N_exp=1 --type_model=SGC --dataset=WISCONSIN
+-------------------+---------------------+
| Parameter         | Value               |
+-------------------+---------------------+
| N_exp             | 1                   |
+-------------------+---------------------+
| activation        | relu                |
+-------------------+---------------------+
| adj_dropout       | 0.500               |
+-------------------+---------------------+
| alpha             | 0.100               |
+-------------------+---------------------+
| compare_model     | 1                   |
+-------------------+---------------------+
| cuda              | 1                   |
+-------------------+---------------------+
| cuda_num          | 0                   |
+-------------------+---------------------+
| dataset           | WISCONSIN           |
+-------------------+---------------------+
| dim_hidden        | 64                  |
+-------------------+---------------------+
| dropout           | 0.500               |
+-------------------+---------------------+
| edge_dropout      | 0.200               |
+-------------------+---------------------+
| embedding_dropout | 0.600               |
+-------------------+---------------------+
| epochs            | 1000                |
+-------------------+---------------------+
| graph_dropout     | 0.200               |
+-------------------+---------------------+
| has_residual_MLP  | 0                   |
+-------------------+---------------------+
| lamda             | 0.500               |
+-------------------+---------------------+
| layer_agg         | concat              |
+-------------------+---------------------+
| layerwise_dropout | 0                   |
+-------------------+---------------------+
| log_file_name     | time_and_memory.log |
+-------------------+---------------------+
| lr                | 0.010               |
+-------------------+---------------------+
| multi_label       | 0                   |
+-------------------+---------------------+
| node_norm_type    | n                   |
+-------------------+---------------------+
| num_classes       | 5                   |
+-------------------+---------------------+
| num_feats         | 1703                |
+-------------------+---------------------+
| num_groups        | None                |
+-------------------+---------------------+
| num_layers        | 64                  |
+-------------------+---------------------+
| patience          | 100                 |
+-------------------+---------------------+
| random_seed       | 100                 |
+-------------------+---------------------+
| res_alpha         | 0.900               |
+-------------------+---------------------+
| resume            | 0                   |
+-------------------+---------------------+
| skip_weight       | None                |
+-------------------+---------------------+
| transductive      | 1                   |
+-------------------+---------------------+
| type_model        | SGC                 |
+-------------------+---------------------+
| type_norm         | None                |
+-------------------+---------------------+
| type_trick        | None                |
+-------------------+---------------------+
| weight_decay      | 0.001               |
+-------------------+---------------------+
| weight_decay1     | 0.010               |
+-------------------+---------------------+
| weight_decay2     | 0.001               |
+-------------------+---------------------+
seed (which_run) = <0>
Epoch: 000, Train loss: 1.6096, Val loss: 1.5998, Test acc: 0.5294
Epoch: 001, Train loss: 1.5986, Val loss: 1.5910, Test acc: 0.5294
Epoch: 020, Train loss: 1.4470, Val loss: 1.4607, Test acc: 0.5490
Epoch: 040, Train loss: 1.3662, Val loss: 1.3827, Test acc: 0.5686
Epoch: 060, Train loss: 1.3325, Val loss: 1.3432, Test acc: 0.5294
Epoch: 080, Train loss: 1.2818, Val loss: 1.3247, Test acc: 0.5098
Epoch: 100, Train loss: 1.2890, Val loss: 1.3151, Test acc: 0.4706
Epoch: 120, Train loss: 1.2786, Val loss: 1.3095, Test acc: 0.4510
Epoch: 140, Train loss: 1.2696, Val loss: 1.3056, Test acc: 0.4314
Epoch: 160, Train loss: 1.2499, Val loss: 1.3027, Test acc: 0.4314
Epoch: 180, Train loss: 1.2727, Val loss: 1.2998, Test acc: 0.4314
Epoch: 200, Train loss: 1.2829, Val loss: 1.2977, Test acc: 0.4314
Epoch: 220, Train loss: 1.2436, Val loss: 1.2973, Test acc: 0.4314
Epoch: 240, Train loss: 1.2572, Val loss: 1.2961, Test acc: 0.4314
Epoch: 260, Train loss: 1.2587, Val loss: 1.2953, Test acc: 0.4314
Epoch: 280, Train loss: 1.2539, Val loss: 1.2946, Test acc: 0.4314
Epoch: 300, Train loss: 1.2433, Val loss: 1.2923, Test acc: 0.4314
Epoch: 320, Train loss: 1.2416, Val loss: 1.2920, Test acc: 0.4510
Epoch: 340, Train loss: 1.2549, Val loss: 1.2920, Test acc: 0.4510
Epoch: 360, Train loss: 1.2425, Val loss: 1.2912, Test acc: 0.4510
Epoch: 380, Train loss: 1.2366, Val loss: 1.2906, Test acc: 0.4510
Epoch: 400, Train loss: 1.2499, Val loss: 1.2900, Test acc: 0.4510
Epoch: 420, Train loss: 1.2510, Val loss: 1.2902, Test acc: 0.4510
Epoch: 440, Train loss: 1.2531, Val loss: 1.2900, Test acc: 0.4510
Epoch: 460, Train loss: 1.2536, Val loss: 1.2892, Test acc: 0.4510
Epoch: 480, Train loss: 1.2278, Val loss: 1.2880, Test acc: 0.4510
Epoch: 500, Train loss: 1.2557, Val loss: 1.2881, Test acc: 0.4510
Epoch: 520, Train loss: 1.2390, Val loss: 1.2888, Test acc: 0.4510
Epoch: 540, Train loss: 1.2618, Val loss: 1.2892, Test acc: 0.4510
Epoch: 560, Train loss: 1.2523, Val loss: 1.2893, Test acc: 0.4510
Epoch: 580, Train loss: 1.2349, Val loss: 1.2899, Test acc: 0.4510
train_loss: 1.2571, val_acc: 0.5500, test_acc:0.4510
mean and std of test acc: 0.4510±0.0000
final mean and std of test acc with <1> runs: 0.4510±0.0000

(base) 192:eegnn yiruiliu$ python main.py --compare_model=1 --cuda_num=0 --N_exp=1 --type_model=SGC_new --dataset=WISCONSIN
+-------------------+---------------------+
| Parameter         | Value               |
+-------------------+---------------------+
| N_exp             | 1                   |
+-------------------+---------------------+
| activation        | relu                |
+-------------------+---------------------+
| adj_dropout       | 0.500               |
+-------------------+---------------------+
| alpha             | 0.100               |
+-------------------+---------------------+
| compare_model     | 1                   |
+-------------------+---------------------+
| cuda              | 1                   |
+-------------------+---------------------+
| cuda_num          | 0                   |
+-------------------+---------------------+
| dataset           | WISCONSIN           |
+-------------------+---------------------+
| dim_hidden        | 64                  |
+-------------------+---------------------+
| dropout           | 0.500               |
+-------------------+---------------------+
| edge_dropout      | 0.200               |
+-------------------+---------------------+
| embedding_dropout | 0.600               |
+-------------------+---------------------+
| epochs            | 1000                |
+-------------------+---------------------+
| graph_dropout     | 0.200               |
+-------------------+---------------------+
| has_residual_MLP  | 0                   |
+-------------------+---------------------+
| lamda             | 0.500               |
+-------------------+---------------------+
| layer_agg         | concat              |
+-------------------+---------------------+
| layerwise_dropout | 0                   |
+-------------------+---------------------+
| log_file_name     | time_and_memory.log |
+-------------------+---------------------+
| lr                | 0.010               |
+-------------------+---------------------+
| multi_label       | 0                   |
+-------------------+---------------------+
| node_norm_type    | n                   |
+-------------------+---------------------+
| num_classes       | 5                   |
+-------------------+---------------------+
| num_feats         | 1703                |
+-------------------+---------------------+
| num_groups        | None                |
+-------------------+---------------------+
| num_layers        | 64                  |
+-------------------+---------------------+
| patience          | 100                 |
+-------------------+---------------------+
| random_seed       | 100                 |
+-------------------+---------------------+
| res_alpha         | 0.900               |
+-------------------+---------------------+
| resume            | 0                   |
+-------------------+---------------------+
| skip_weight       | None                |
+-------------------+---------------------+
| transductive      | 1                   |
+-------------------+---------------------+
| type_model        | SGC_new             |
+-------------------+---------------------+
| type_norm         | None                |
+-------------------+---------------------+
| type_trick        | None                |
+-------------------+---------------------+
| weight_decay      | 0.001               |
+-------------------+---------------------+
| weight_decay1     | 0.010               |
+-------------------+---------------------+
| weight_decay2     | 0.001               |
+-------------------+---------------------+
seed (which_run) = <0>
Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/new_data/wisconsin/out1_node_feature_label.txt
Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/new_data/wisconsin/out1_graph_edges.txt
Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_0.npz
Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_1.npz
Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_2.npz
Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_3.npz
Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_4.npz
Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_5.npz
Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_6.npz
Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_7.npz
Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_8.npz
Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_9.npz
Processing...
Done!
is symmetric: (0 is yes) tensor(0.)
is self connected: 0 is no tensor(251.)
Num Nodes : 251          Num Edges : 482
Epoch: 000, Train loss: 1.6095, Val loss: 1.6033, Test acc: 0.5294
Epoch: 001, Train loss: 1.6037, Val loss: 1.5975, Test acc: 0.5294
Epoch: 020, Train loss: 1.5222, Val loss: 1.5148, Test acc: 0.5490
Epoch: 040, Train loss: 1.4738, Val loss: 1.4632, Test acc: 0.5686
Epoch: 060, Train loss: 1.4369, Val loss: 1.4291, Test acc: 0.5686
Epoch: 080, Train loss: 1.4116, Val loss: 1.4045, Test acc: 0.5686
Epoch: 100, Train loss: 1.4004, Val loss: 1.3859, Test acc: 0.5686
Epoch: 120, Train loss: 1.3937, Val loss: 1.3714, Test acc: 0.5686
Epoch: 140, Train loss: 1.3804, Val loss: 1.3604, Test acc: 0.5686
Epoch: 160, Train loss: 1.3719, Val loss: 1.3514, Test acc: 0.5686
Epoch: 180, Train loss: 1.3759, Val loss: 1.3451, Test acc: 0.5686
Epoch: 200, Train loss: 1.3661, Val loss: 1.3391, Test acc: 0.5686
Epoch: 220, Train loss: 1.3610, Val loss: 1.3342, Test acc: 0.5686
Epoch: 240, Train loss: 1.3699, Val loss: 1.3301, Test acc: 0.5686
Epoch: 260, Train loss: 1.3530, Val loss: 1.3269, Test acc: 0.5686
Epoch: 280, Train loss: 1.3480, Val loss: 1.3244, Test acc: 0.5686
Epoch: 300, Train loss: 1.3539, Val loss: 1.3220, Test acc: 0.5686
Epoch: 320, Train loss: 1.3392, Val loss: 1.3200, Test acc: 0.5686
Epoch: 340, Train loss: 1.3538, Val loss: 1.3186, Test acc: 0.5686
Epoch: 360, Train loss: 1.3396, Val loss: 1.3170, Test acc: 0.5686
Epoch: 380, Train loss: 1.3467, Val loss: 1.3159, Test acc: 0.5686
Epoch: 400, Train loss: 1.3529, Val loss: 1.3149, Test acc: 0.5490
Epoch: 420, Train loss: 1.3291, Val loss: 1.3137, Test acc: 0.5490
Epoch: 440, Train loss: 1.3377, Val loss: 1.3122, Test acc: 0.5490
Epoch: 460, Train loss: 1.3315, Val loss: 1.3117, Test acc: 0.5490
Epoch: 480, Train loss: 1.3395, Val loss: 1.3109, Test acc: 0.5490
Epoch: 500, Train loss: 1.3324, Val loss: 1.3102, Test acc: 0.5490
Epoch: 520, Train loss: 1.3505, Val loss: 1.3097, Test acc: 0.5686
Epoch: 540, Train loss: 1.3457, Val loss: 1.3099, Test acc: 0.5686
Epoch: 560, Train loss: 1.3441, Val loss: 1.3097, Test acc: 0.5686
Epoch: 580, Train loss: 1.3297, Val loss: 1.3096, Test acc: 0.5686
Epoch: 600, Train loss: 1.3425, Val loss: 1.3088, Test acc: 0.5686
Epoch: 620, Train loss: 1.3342, Val loss: 1.3085, Test acc: 0.5686
Epoch: 640, Train loss: 1.3396, Val loss: 1.3086, Test acc: 0.5686
Epoch: 660, Train loss: 1.3371, Val loss: 1.3081, Test acc: 0.5686
Epoch: 680, Train loss: 1.3619, Val loss: 1.3082, Test acc: 0.5686
Epoch: 700, Train loss: 1.3192, Val loss: 1.3081, Test acc: 0.5490
Epoch: 720, Train loss: 1.3562, Val loss: 1.3074, Test acc: 0.5490
Epoch: 740, Train loss: 1.3435, Val loss: 1.3079, Test acc: 0.5490
Epoch: 760, Train loss: 1.3430, Val loss: 1.3078, Test acc: 0.5490
Epoch: 780, Train loss: 1.3312, Val loss: 1.3079, Test acc: 0.5490
Epoch: 800, Train loss: 1.3428, Val loss: 1.3079, Test acc: 0.5490
train_loss: 1.3366, val_acc: 0.5375, test_acc:0.5490
mean and std of test acc: 0.5490±0.0000
final mean and std of test acc with <1> runs: 0.5490±0.0000


